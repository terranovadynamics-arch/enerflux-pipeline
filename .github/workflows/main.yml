name: Enerflux Data Pipeline (Daily)

on:
  workflow_dispatch:  # Manual trigger
  schedule:
    - cron: '0 12 * * *'  # Daily at 12:00 UTC (adjust to your timezone)

jobs:
  data-collection:
    runs-on: ubuntu-latest
    timeout-minutes: 30  # Prevent hanging jobs
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            echo "Installing minimum required packages"
            pip install pandas requests
          fi

      - name: Create output directories
        run: |
          mkdir -p pipeline/outputs
          mkdir -p pipeline/logs

      - name: Verify environment
        run: |
          echo "Python version: $(python --version)"
          echo "Pip version: $(pip --version)"
          echo "Directory structure:"
          find . -name "*.py" -path "*/pipeline/*" | head -10

      - name: Execute data pipeline
        run: |
          set -e  # Exit immediately on error
          if [ -f "ci_run.py" ]; then
            echo "Running via ci_run.py"
            python ci_run.py daily
          else
            echo "Running fred_wti.py directly"
            python pipeline/collectors/fred_wti.py
          fi
          
      - name: Verify output
        run: |
          echo "Generated files:"
          ls -la pipeline/outputs/ || echo "No outputs directory"
          if [ -f "pipeline/outputs/WTI_DAILY_latest.csv" ]; then
            echo "Output file details:"
            wc -l pipeline/outputs/WTI_DAILY_latest.csv
            head -3 pipeline/outputs/WTI_DAILY_latest.csv
          fi

      - name: Upload artifacts (optional)
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: wti-data
          path: pipeline/outputs/
          retention-days: 7name: Enerflux Data Machine

on:
  workflow_dispatch:
    inputs:
      job:
        description: "Job to run"
        type: choice
        required: true
        default: daily
        options:
          - daily
          - weekly
  schedule:
    - cron: '0 0 * * *'      # Daily à 00:00 UTC (01:00 à Tunis)
    - cron: '30 5 * * MON'   # Weekly le lundi 05:30 UTC

jobs:
  run-pipeline:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            pip install pandas requests boto3 botocore matplotlib

      - name: Prepare output dir
        run: mkdir -p pipeline/outputs

      - name: Debug tree (first runs only - optional)
        if: ${{ github.event_name == 'workflow_dispatch' }}
        run: |
          pwd
          ls -la
          echo "----- pipeline -----"; ls -la pipeline || true
          echo "----- outputs  -----"; ls -la pipeline/outputs || true

      - name: Run pipeline (daily/weekly)
        env:
          R2_ACCOUNT_ID: ${{ secrets.R2_ACCOUNT_ID }}
          R2_BUCKET: ${{ secrets.R2_BUCKET }}
          R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
        run: |
          job="${{ inputs.job }}"
          if [ -z "$job" ]; then
            # si CRON: weekly le lundi 05h30 UTC, sinon daily
            day=$(date -u +%u); hour=$(date -u +%H%M)
            if [ "$day" = "1" ] && [ "$hour" = "0530" ]; then
              job="weekly"
            else
              job="daily"
            fi
          fi
          echo "Running job=$job"
          python ci_run.py "$job"
