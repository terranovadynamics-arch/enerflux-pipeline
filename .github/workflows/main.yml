name: Enerflux Data Machine

on:
  workflow_dispatch:
    inputs:
      job:
        description: "Job to run"
        type: choice
        required: true
        default: daily
        options: [daily, weekly]
  schedule:
    - cron: '0 0 * * *'      # daily 00:00 UTC
    - cron: '30 5 * * MON'   # weekly Monday 05:30 UTC

jobs:
  run-pipeline:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install deps
        shell: bash
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            pip install pandas requests boto3 botocore matplotlib
          fi

      - name: Ensure outputs dir
        run: mkdir -p pipeline/outputs

      - name: Run pipeline
        env:
          # Cloudflare R2 (si déjà en place)
          R2_ACCOUNT_ID: ${{ secrets.R2_ACCOUNT_ID }}
          R2_BUCKET: ${{ secrets.R2_BUCKET }}
          R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          # Nasdaq Data Link
          NDL_API_KEY: ${{ secrets.NDL_API_KEY }}
        shell: bash
        run: |
          job="${{ inputs.job }}"
          if [ -z "$job" ]; then job="daily"; fi
          echo "Running job=$job"
          python ci_run.py "$job"
